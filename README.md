# Серверная архитектура Tanks Blitz (Прототип)

Этот проект представляет собой прототип серверной архитектуры для многопользовательской игры Tanks Blitz, разработанный на Python.
Он включает компоненты для аутентификации, игровой логики, масштабирования, мониторинга и резервного копирования.

## Обзор проекта

Цель проекта - продемонстрировать построение серверной части для MMO-игры с учетом современных практик и технологий, таких как:
- Разделение сервисов (аутентификация, игра)
- Асинхронное программирование
- Паттерны проектирования (Singleton, Object Pool)
- Контейнеризация (Docker)
- Оркестрация (Kubernetes)
- Мониторинг (Prometheus, Grafana)
- Защита от DDoS (Nginx)
- Резервное копирование (Redis)

## Архитектура

Система состоит из следующих основных компонентов:

1.  **Клиент Игры** (не входит в этот репозиторий)
2.  **Nginx (Входная точка/Балансировщик/Защита от DDoS):**
    *   Принимает весь трафик от клиентов.
    *   Проксирует TCP-трафик на Сервер Аутентификации.
    *   Проксирует UDP-трафик на Игровой Сервер.
    *   Может быть настроен для базовой защиты от DDoS.
    *   Разворачивается в Kubernetes.
3.  **Сервер Аутентификации (Auth Server):**
    *   **Протокол: TCP, текстовый.**
    *   **Формат команд:** `LOGIN <имя_пользователя> <пароль>` (например, `LOGIN player1 password123`). Команда должна завершаться переводом строки при ручном тестировании через `echo` или `telnet` (нажатием Enter).
    *   Назначение: Регистрация (в текущей реализации заглушка) и аутентификация пользователей. В реальной системе генерировал бы сессионные токены.
    *   Технологии: Python, `asyncio`.
    *   Экспортирует метрики для Prometheus на порт `8000`.
4.  **Игровой Сервер (Game Server):**
    *   **Протокол: UDP, сообщения в формате JSON.**
    *   **Формат сообщений:** Каждое сообщение - это JSON-объект, например, `{"action": "join_game", "player_id": "some_player_id"}`.
    *   Назначение: Обработка игровой логики, синхронизация состояния игры.
    *   Паттерны:
        *   `SessionManager` (Singleton) для управления активными игровыми сессиями.
        *   `TankPool` (Object Pool) для управления объектами танков.
    *   Дельта-обновления: Концептуально заложены, но требуют полной реализации.
    *   Технологии: Python, `asyncio`.
    *   Экспортирует метрики для Prometheus на порт `8001`.
5.  **Redis:**
    *   Назначение: Кэширование, хранение временных данных сессий (если необходимо).
    *   Persistence: Настроен для RDB снапшотов и AOF логов.
    *   Резервное копирование: Автоматизировано через Kubernetes CronJob.
6.  **Prometheus:**
    *   Сбор метрик со всех серверных компонентов.
7.  **Grafana:**
    *   Визуализация метрик из Prometheus, создание дашбордов.
8.  **База данных (PostgreSQL - концептуально):**
    *   Предполагается для хранения данных пользователей, но в текущем прототипе сервер аутентификации использует заглушку (`MOCK_USERS_DB`). Для полноценной реализации потребуется интеграция с реальной БД.

### Структура проекта

- `auth_server/`: Код сервера аутентификации.
  - `main.py`: Точка входа, запуск TCP-сервера.
  - `tcp_handler.py`: Логика обработки TCP-соединений и команд.
  - `user_service.py`: Логика аутентификации (сейчас заглушка).
  - `metrics.py`: Определения метрик Prometheus.
- `game_server/`: Код игрового сервера.
  - `main.py`: Точка входа, запуск UDP-сервера.
  - `udp_handler.py`: Логика обработки UDP-пакетов и игровой логики.
  - `session_manager.py`: Управление игровыми сессиями (Singleton).
  - `tank_pool.py`: Управление объектами танков (Object Pool).
  - `tank.py`: Класс, представляющий танк.
  - `metrics.py`: Определения метрик Prometheus.
- `core/`: Общие модули (например, `redis_client.py`).
- `tests/`: Юнит и нагрузочные тесты.
  - `unit/`: Юнит-тесты (`pytest`).
  - `load/`: Нагрузочные тесты (`locust`).
- `monitoring/`: Конфигурации для Prometheus (`prometheus.yml`) и Grafana.
- `deployment/`: Dockerfile, скрипты и манифесты Kubernetes, конфигурации Nginx и Redis.
- `README.md`: Этот файл.
- `requirements.txt`: Зависимости Python.
- `docker-compose.yml`: Для локального запуска Prometheus и Grafana.

## Требования

- Python 3.9+
- Docker
- `kubectl` (для развертывания в Kubernetes)
- Доступ к кластеру Kubernetes (например, Minikube, Kind, или облачный EKS, GKE, AKS)
- `locust` (для запуска нагрузочных тестов)
- `netcat` (`nc`) или `telnet` (для ручного тестирования TCP/UDP)

## Установка зависимостей

```bash
pip install -r requirements.txt
```

## Локальный запуск серверов (для разработки)

**Сервер аутентификации:**
```bash
python -m auth_server.main
```
Сервер будет доступен по TCP на `localhost:8888`. Метрики Prometheus на `http://localhost:8000/metrics`.

**Игровой сервер:**
```bash
python -m game_server.main
```
Сервер будет доступен по UDP на `localhost:9999`. Метрики Prometheus на `http://localhost:8001/metrics`.

## Ручное тестирование и отладка

### Общие советы по отладке:
- **Проверяйте логи серверов:** Серверы настроены на подробное логирование (уровень DEBUG). Вся активность, ошибки, полученные данные и отправленные ответы должны там отображаться.
- **Формат данных:** Убедитесь, что вы отправляете данные в ожидаемом сервером формате (текстовая команда для Auth Server, JSON для Game Server).
- **Кодировка:** Все текстовые данные должны быть в UTF-8.
- **Проверка портов:** Убедитесь, что порты (8888, 9999, 8000, 8001) не заняты другими приложениями.
  ```bash
  # Для Windows (PowerShell)
  netstat -ano | findstr :8888
  netstat -ano | findstr :9999
  # Для Linux/macOS
  sudo netstat -tulnp | grep :8888
  sudo netstat -tulnp | grep :9999
  ```
- **Сетевой анализатор (Wireshark):** Если возникают трудно диагностируемые проблемы с сетью или форматом пакетов, Wireshark может помочь увидеть, что именно передается по сети.

### Тестирование Сервера Аутентификации (TCP)
- **Запустите сервер:** `python -m auth_server.main`
- **Способ 1: `netcat` (nc)**
  ```bash
  # Успешная аутентификация (замените player1 и password123 на данные из MOCK_USERS_DB)
  echo "LOGIN player1 password123" | nc localhost 8888
  # Ожидаемый ответ: AUTH_SUCCESS Пользователь player1 успешно аутентифицирован.

  # Неверный пароль
  echo "LOGIN player1 wrongpassword" | nc localhost 8888
  # Ожидаемый ответ: AUTH_FAILURE Неверный пароль.

  # Несуществующий пользователь
  echo "LOGIN nonexist foobar" | nc localhost 8888
  # Ожидаемый ответ: AUTH_FAILURE Пользователь не найден.

  # Неверный формат команды
  echo "REGISTER player1 password123" | nc localhost 8888
  # Ожидаемый ответ: INVALID_COMMAND Формат: LOGIN username password
  ```
  *Примечание: `echo` добавляет `
` в конце, что хорошо для TCP.*
- **Способ 2: `telnet`**
  ```bash
  telnet localhost 8888
  ```
  После подключения вводите команды вручную и нажимайте Enter:
  ```
  LOGIN player1 password123
  ```
  Затем `Ctrl+]` и `quit` для выхода из telnet.

### Тестирование Игрового Сервера (UDP)
- **Запустите сервер:** `python -m game_server.main`
- **Способ 1: `netcat` (nc) для UDP**
  ```bash
  # Присоединение игрока (замените player_id_test на уникальный ID)
  echo '{"action": "join_game", "player_id": "player_id_test"}' | nc -u localhost 9999
  # Ожидаемый ответ (если сервер отвечает на join, текущая реализация отвечает): 
  # {"status": "joined", "session_id": "...", "tank_id": "...", "initial_state": {...}}

  # Движение (замените player_id_test)
  echo '{"action": "move", "player_id": "player_id_test", "position": [10,20]}' | nc -u localhost 9999
  # На это действие сервер может не отвечать напрямую клиенту, а рассылать обновления другим. Проверяйте логи.

  # Невалидный JSON
  echo 'Это не JSON' | nc -u localhost 9999
  # Проверяйте логи сервера на наличие `ERROR - Невалидный JSON получен`.
  ```
  *Примечание: Для UDP `nc` отправляет пакет и завершается. Ответы нужно смотреть в логах сервера или ожидать их в отдельном слушающем процессе, если сервер их шлет.*
- **Способ 2: Python-скрипт (см. `tests/load/send_udp_test.py` для примера)**
  Вы можете адаптировать скрипт `send_udp_test.py` для отправки специфичных UDP-сообщений и логирования ответов, если они есть.


## Сборка и запуск с Docker

1.  **Собрать Docker образ:**
    Замените `your_image_name` на желаемое имя образа.
    ```bash
    docker build -t your_image_name:latest .
    ```

2.  **Запустить контейнер сервера аутентификации:**
    ```bash
    docker run -p 8888:8888 -p 8000:8000 your_image_name:latest auth
    ```

3.  **Запустить контейнер игрового сервера:**
    ```bash
    docker run -p 9999:9999/udp -p 8001:8001 your_image_name:latest game
    ```

## Развертывание в Kubernetes

Все необходимые манифесты находятся в директории `deployment/kubernetes/`.

**Предварительные шаги:**

1.  **Настройте `kubectl`** для работы с вашим кластером Kubernetes.
2.  **Соберите и загрузите Docker образ** (`your_image_name:latest`) в репозиторий образов, доступный вашему кластеру Kubernetes (например, Docker Hub, AWS ECR, Google GCR). Обновите имя образа в файлах `*.deployment.yaml`.
    *   Если вы используете локальный кластер типа Minikube, вы можете собрать образ непосредственно в Docker-демоне Minikube: `eval $(minikube -p minikube docker-env)` перед `docker build`. В этом случае `imagePullPolicy: IfNotPresent` в Deployment'ах может быть достаточно.

**Порядок развертывания компонентов:**

(См. предыдущую версию README для детального порядка `kubectl apply ...`)
Порядок: ConfigMaps (Nginx, Redis) -> PVC (Redis) -> Redis (Deployment, Service) -> Приложения (Auth, Game Deployments & Services) -> Nginx (Deployment, Service).

**Доступ к сервисам:**
- После развертывания Nginx с `type: LoadBalancer`, внешний IP-адрес Nginx будет точкой входа для TCP (порт 8888) и UDP (порт 9999) трафика.
- Метрики серверов (Auth:8000, Game:8001) будут доступны внутри кластера через их сервисы или через Nginx, если настроить для них проксирование.

## Мониторинг (Prometheus и Grafana)

1.  **Развертывание Prometheus и Grafana (локально):**
    Используйте `docker-compose.yml` из корня проекта:
    ```bash
    docker-compose up -d
    ```
    *Примечание: Убедитесь, что в `monitoring/prometheus/prometheus.yml` правильно указаны адреса ваших локально запущенных серверов (например, `host.docker.internal:8000` если серверы на хосте, а Prometheus в Docker на Windows/Mac, или `localhost:8000` если используется `network_mode: host` на Linux).*

2.  **Настройка Grafana:**
    - Откройте Grafana: `http://localhost:3000` (логин/пароль по умолчанию: admin/admin).
    - Добавить Prometheus как источник данных (URL: `http://prometheus:9090`).
    - Импортировать или создать дашборды для визуализации метрик.

## Тестирование

**Юнит-тесты:**
```bash
sh run_tests.sh
# или напрямую:
# pytest -v tests/unit/
```

**Нагрузочные тесты (Locust):**
Требуют запущенных серверов.
1.  **Для сервера аутентификации:**
    - Запустите Auth Server.
    - `locust -f tests/load/locustfile_auth.py AuthUser --host <auth_server_host>`
2.  **Для игрового сервера:**
    - Запустите Game Server.
    - `locust -f tests/load/locustfile_game.py GameUser --host <game_server_host>`
Откройте веб-интерфейс Locust (обычно `http://localhost:8089`).

## Резервное копирование Redis

- Redis настроен на использование RDB снапшотов и AOF логов для персистентности.
- Kubernetes CronJob (`deployment/kubernetes/redis_backup_cronjob.yaml`) настроен для выполнения скрипта резервного копирования.
- **Важно:** Место для хранения бэкапов (`backup-target-storage` в CronJob) должно быть настроено на использование надежного внешнего хранилища.

## Дальнейшие улучшения и TODO

- **Полная интеграция базы данных (PostgreSQL)** для сервера аутентификации.
- **Реализация системы токенов** (JWT) для аутентификации и авторизации.
- **Детализированная реализация дельта-обновлений** на игровом сервере.
- **Более сложная игровая логика.**
- **Матчмейкинг.**
- **Защищенное хранение секретов** в Kubernetes.
- **Настройка HTTPS/TLS** для Nginx и эндпоинтов метрик.
- **Централизованный сбор и анализ логов** (ELK Stack, Grafana Loki).
- **Улучшение скриптов резервного копирования и тестирование восстановления.**
- **Helm-чарт** для упрощения развертывания.
